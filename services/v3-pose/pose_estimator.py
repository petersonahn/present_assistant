"""
Human Pose Estimation using OpenVINO
ì‹¤ì‹œê°„ ë©´ì ‘ í”¼ë“œë°± ì‹œìŠ¤í…œ - í¬ì¦ˆ ê°ì§€ ëª¨ë“ˆ
"""

import cv2
import numpy as np
from openvino.runtime import Core
from typing import List, Tuple, Dict, Optional
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HumanPoseEstimator:
    """OpenVINO ê¸°ë°˜ ì¸ê°„ í¬ì¦ˆ ì¶”ì • í´ë˜ìŠ¤"""
    
    # COCO í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ ì¸ë±ìŠ¤ (18ê°œ ê´€ì ˆ)
    POSE_PAIRS = [
        (1, 2), (1, 5), (2, 3), (3, 4), (5, 6), (6, 7),
        (1, 8), (8, 9), (9, 10), (1, 11), (11, 12), (12, 13),
        (1, 0), (0, 14), (14, 16), (0, 15), (15, 17)
    ]
    
    # í‚¤í¬ì¸íŠ¸ ì´ë¦„ ë§¤í•‘
    KEYPOINT_NAMES = [
        "nose", "neck", "r_shoulder", "r_elbow", "r_wrist",
        "l_shoulder", "l_elbow", "l_wrist", "r_hip", "r_knee",
        "r_ankle", "l_hip", "l_knee", "l_ankle", "r_eye",
        "l_eye", "r_ear", "l_ear"
    ]
    
    def __init__(self, model_xml_path: str, model_bin_path: str, device: str = "CPU"):
        """
        í¬ì¦ˆ ì¶”ì •ê¸° ì´ˆê¸°í™”
        
        Args:
            model_xml_path: OpenVINO XML ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            model_bin_path: OpenVINO BIN ëª¨ë¸ íŒŒì¼ ê²½ë¡œ 
            device: ì¶”ë¡  ë””ë°”ì´ìŠ¤ ("CPU", "GPU", "MYRIAD" ë“±)
        """
        self.device = device
        self.model_xml_path = model_xml_path
        self.model_bin_path = model_bin_path
        
        # OpenVINO ì½”ì–´ ë° ëª¨ë¸ ë¡œë“œ
        self.core = Core()
        self.model = self.core.read_model(model_xml_path)
        self.compiled_model = self.core.compile_model(self.model, device)
        
        # ì…ì¶œë ¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        self.input_layer = self.compiled_model.input(0)
        self.output_layer = self.compiled_model.output(0)
        
        # ì…ë ¥ í¬ê¸° ì •ë³´
        self.input_shape = self.input_layer.shape
        self.input_height = self.input_shape[2]  # 256
        self.input_width = self.input_shape[3]   # 456
        
        logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_xml_path}")
        logger.info(f"ì…ë ¥ í¬ê¸°: {self.input_width}x{self.input_height}")
        logger.info(f"ë””ë°”ì´ìŠ¤: {device}")
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ìµœì í™”ë¨)
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR í˜•ì‹)
            
        Returns:
            ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ
        """
        # í¬ê¸° ì¡°ì •ì„ ë¨¼ì € ìˆ˜í–‰ (ì‘ì€ ì´ë¯¸ì§€ì—ì„œ ìƒ‰ìƒ ë³€í™˜ì´ ë” ë¹ ë¦„)
        resized_image = cv2.resize(image, (self.input_width, self.input_height), interpolation=cv2.INTER_LINEAR)
        
        # BGRì„ RGBë¡œ ë³€í™˜í•˜ë©´ì„œ ë™ì‹œì— ì •ê·œí™”
        # OpenCVëŠ” BGRì´ë¯€ë¡œ ì±„ë„ ìˆœì„œë¥¼ ë°”ê¿”ì„œ ì •ê·œí™”
        input_tensor = np.empty((1, 3, self.input_height, self.input_width), dtype=np.float32)
        
        # B, G, R ì±„ë„ì„ R, G, B ìˆœì„œë¡œ ë³€í™˜í•˜ë©´ì„œ ì •ê·œí™” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        input_tensor[0, 0] = resized_image[:, :, 2] / 255.0  # R
        input_tensor[0, 1] = resized_image[:, :, 1] / 255.0  # G  
        input_tensor[0, 2] = resized_image[:, :, 0] / 255.0  # B
        
        return input_tensor
    
    def postprocess_output(self, output: np.ndarray, original_shape: Tuple[int, int]) -> List[Dict]:
        """
        ëª¨ë¸ ì¶œë ¥ í›„ì²˜ë¦¬ (ìµœì í™”ë¨)
        
        Args:
            output: ëª¨ë¸ ì¶œë ¥ í…ì„œ
            original_shape: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (height, width)
            
        Returns:
            ê°ì§€ëœ í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        original_height, original_width = original_shape
        
        # ì¶œë ¥ í˜•íƒœ: [1, 38, 32, 57] (PAFs + keypoints heatmaps)
        # í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ ì¶”ì¶œ (ì±„ë„ 19-37, ì¸ë±ìŠ¤ 19:38)
        keypoint_heatmaps = output[0, 19:38]  # ë°°ì¹˜ ì°¨ì› ì œê±°ì™€ ë™ì‹œì— ìŠ¬ë¼ì´ì‹±
        
        # ìŠ¤ì¼€ì¼ íŒ©í„° ë¯¸ë¦¬ ê³„ì‚°
        heatmap_height, heatmap_width = keypoint_heatmaps.shape[1:]
        scale_x = original_width / heatmap_width
        scale_y = original_height / heatmap_height
        
        keypoints = []
        confidence_threshold = 0.05  # ì„ê³„ê°’ì„ ë‚®ì¶°ì„œ ë” ë§ì€ í‚¤í¬ì¸íŠ¸ ê°ì§€
        
        # ë²¡í„°í™”ëœ ì²˜ë¦¬ë¡œ ìµœì í™”
        for i in range(1, len(keypoint_heatmaps)):  # ë°°ê²½(0ë²ˆ) ì œì™¸
            heatmap = keypoint_heatmaps[i]
            
            # argmaxë¥¼ ì‚¬ìš©í•´ì„œ ìµœëŒ€ê°’ ìœ„ì¹˜ ì°¾ê¸° (ë” ë¹ ë¦„)
            max_idx = np.unravel_index(np.argmax(heatmap), heatmap.shape)
            max_val = heatmap[max_idx]
            
            # ì‹ ë¢°ë„ ì„ê³„ê°’ ì²´í¬
            if max_val > confidence_threshold:
                # ì¢Œí‘œ ë³€í™˜ (ì •ìˆ˜ ì—°ì‚° ìµœì†Œí™”)
                x = int(max_idx[1] * scale_x)
                y = int(max_idx[0] * scale_y)
                
                keypoints.append({
                    'id': i - 1,  # 0-17 ì¸ë±ìŠ¤ë¡œ ì¡°ì •
                    'name': self.KEYPOINT_NAMES[i - 1],
                    'x': x,
                    'y': y,
                    'confidence': float(max_val)
                })
        
        return keypoints
    
    def estimate_pose(self, image: np.ndarray) -> Dict:
        """
        ì´ë¯¸ì§€ì—ì„œ í¬ì¦ˆ ì¶”ì • ìˆ˜í–‰
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR í˜•ì‹)
            
        Returns:
            í¬ì¦ˆ ì¶”ì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        original_height, original_width = image.shape[:2]
        
        # ì „ì²˜ë¦¬
        input_tensor = self.preprocess_image(image)
        
        # ì¶”ë¡  ì‹¤í–‰
        result = self.compiled_model([input_tensor])
        output = result[self.output_layer]
        
        # í›„ì²˜ë¦¬
        keypoints = self.postprocess_output(output, (original_height, original_width))
        
        # í¬ì¦ˆ ë¶„ì„
        pose_analysis = self.analyze_pose(keypoints)
        
        return {
            'keypoints': keypoints,
            'analysis': pose_analysis,
            'image_shape': (original_height, original_width)
        }
    
    def analyze_pose(self, keypoints: List[Dict]) -> Dict:
        """
        í¬ì¦ˆ ë¶„ì„ ë° í”¼ë“œë°± ìƒì„±
        
        Args:
            keypoints: ê°ì§€ëœ í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í¬ì¦ˆ ë¶„ì„ ê²°ê³¼
        """
        analysis = {
            'posture_score': 0,
            'shoulder_balance': 'unknown',
            'head_position': 'unknown',
            'arm_position': 'unknown',
            'feedback': []
        }
        
        # í‚¤í¬ì¸íŠ¸ ê°œìˆ˜ í™•ì¸
        if not keypoints or len(keypoints) == 0:
            analysis['feedback'].append('í‚¤í¬ì¸íŠ¸ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ì— ì „ì‹ ì´ ë³´ì´ë„ë¡ ì¡°ì •í•´ì£¼ì„¸ìš”')
            return analysis
        
        # í‚¤í¬ì¸íŠ¸ë¥¼ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘ (ì‹ ë¢°ë„ 0.2 ì´ìƒë§Œ ì‚¬ìš© - ë” ê´€ëŒ€í•˜ê²Œ)
        kp_dict = {kp['name']: kp for kp in keypoints if kp.get('confidence', 0) > 0.2}
        
        logger.info(f"ì „ì²´ í‚¤í¬ì¸íŠ¸ ê°œìˆ˜: {len(keypoints)}")
        logger.info(f"ì‹ ë¢°ë„ 0.2 ì´ìƒ í‚¤í¬ì¸íŠ¸: {list(kp_dict.keys())}")
        logger.info(f"í‚¤í¬ì¸íŠ¸ ì‹ ë¢°ë„: {[(kp['name'], round(kp['confidence'], 3)) for kp in keypoints[:5]]}")  # ìƒìœ„ 5ê°œë§Œ
        
        try:
            # ê¸°ë³¸ ì ìˆ˜ (í‚¤í¬ì¸íŠ¸ê°€ ê°ì§€ë˜ë©´ 20ì )
            analysis['posture_score'] = 20
            
            # ì–´ê¹¨ ê· í˜• ì²´í¬
            if 'l_shoulder' in kp_dict and 'r_shoulder' in kp_dict:
                left_shoulder = kp_dict['l_shoulder']
                right_shoulder = kp_dict['r_shoulder']
                
                shoulder_diff = abs(left_shoulder['y'] - right_shoulder['y'])
                
                if shoulder_diff < 30:  # ì„ê³„ê°’ì„ 30ìœ¼ë¡œ ì¦ê°€ (ë” ê´€ëŒ€í•˜ê²Œ)
                    analysis['shoulder_balance'] = 'balanced'
                    analysis['posture_score'] += 25
                    analysis['feedback'].append('ì–´ê¹¨ ìœ„ì¹˜ê°€ ê· í˜•ì¡í˜€ ìˆì–´ìš” âœ“')
                else:
                    analysis['shoulder_balance'] = 'unbalanced'
                    analysis['posture_score'] += 10  # ë¶ˆê· í˜•ì´ì–´ë„ ì¼ë¶€ ì ìˆ˜ ë¶€ì—¬
                    analysis['feedback'].append('ì–´ê¹¨ë¥¼ ìˆ˜í‰ìœ¼ë¡œ ë§ì¶°ë³´ì„¸ìš” âš ')
            elif 'neck' in kp_dict:
                # ì–´ê¹¨ê°€ ì—†ì–´ë„ ëª©ì´ ìˆìœ¼ë©´ ë¶€ë¶„ ì ìˆ˜
                analysis['shoulder_balance'] = 'partial'
                analysis['posture_score'] += 15
                analysis['feedback'].append('ì–´ê¹¨ í‚¤í¬ì¸íŠ¸ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤')
            
            # ëª©/ë¨¸ë¦¬ ìœ„ì¹˜ ì²´í¬ (nose ëŒ€ì‹  ë” ë§ì€ ì–¼êµ´ í‚¤í¬ì¸íŠ¸ í™œìš©)
            head_detected = False
            if 'neck' in kp_dict:
                head_points = [kp for name, kp in kp_dict.items() if name in ['nose', 'l_eye', 'r_eye']]
                
                if head_points:
                    neck = kp_dict['neck']
                    # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ì–¼êµ´ í‚¤í¬ì¸íŠ¸ ì‚¬ìš©
                    head_point = max(head_points, key=lambda x: x.get('confidence', 0))
                    
                    # ëª©ê³¼ ì–¼êµ´ì˜ ìˆ˜ì§ ì •ë ¬ ì²´í¬
                    head_tilt = abs(neck['x'] - head_point['x'])
                    
                    if head_tilt < 40:  # ì„ê³„ê°’ì„ 40ìœ¼ë¡œ ì¦ê°€
                        analysis['head_position'] = 'straight'
                        analysis['posture_score'] += 25
                        analysis['feedback'].append('ë¨¸ë¦¬ ìœ„ì¹˜ê°€ ë°”ë¥¸ ìì„¸ì˜ˆìš” âœ“')
                    else:
                        analysis['head_position'] = 'tilted'
                        analysis['posture_score'] += 10
                        analysis['feedback'].append('ë¨¸ë¦¬ë¥¼ ê³§ê²Œ ì„¸ì›Œë³´ì„¸ìš” âš ')
                    head_detected = True
            
            if not head_detected:
                analysis['feedback'].append('ë¨¸ë¦¬ ìœ„ì¹˜ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
            
            # íŒ” ìœ„ì¹˜ ì²´í¬ (ë” ê´€ëŒ€í•œ ì¡°ê±´)
            arm_positions = []
            arms_detected = 0
            
            for side in ['l', 'r']:
                shoulder_key = f'{side}_shoulder'
                elbow_key = f'{side}_elbow'
                wrist_key = f'{side}_wrist'
                
                if shoulder_key in kp_dict:
                    shoulder = kp_dict[shoulder_key]
                    arms_detected += 1
                    
                    if elbow_key in kp_dict:
                        elbow = kp_dict[elbow_key]
                        
                        # íŒ”ê¿ˆì¹˜ê°€ ì–´ê¹¨ë³´ë‹¤ ë§ì´ ìœ„ì— ìˆì§€ ì•Šì€ì§€ ì²´í¬ (ë” ê´€ëŒ€í•˜ê²Œ)
                        if elbow['y'] >= shoulder['y'] - 50:  # 50í”½ì…€ ì—¬ìœ 
                            arm_positions.append('natural')
                        else:
                            arm_positions.append('raised')
                    else:
                        # íŒ”ê¿ˆì¹˜ê°€ ì—†ì–´ë„ ì–´ê¹¨ê°€ ìˆìœ¼ë©´ ë¶€ë¶„ì ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ë‹¤ê³  ê°€ì •
                        arm_positions.append('natural')
            
            if arms_detected > 0:
                if len(arm_positions) > 0:
                    natural_count = arm_positions.count('natural')
                    if natural_count == len(arm_positions):
                        analysis['arm_position'] = 'natural'
                        analysis['posture_score'] += 25
                        analysis['feedback'].append('íŒ” ìì„¸ê°€ ìì—°ìŠ¤ëŸ¬ì›Œìš” âœ“')
                    elif natural_count > 0:
                        analysis['arm_position'] = 'partial'
                        analysis['posture_score'] += 15
                        analysis['feedback'].append('ì¼ë¶€ íŒ” ìì„¸ê°€ ìì—°ìŠ¤ëŸ¬ì›Œìš” ğŸ‘Œ')
                    else:
                        analysis['arm_position'] = 'raised'
                        analysis['posture_score'] += 5
                        analysis['feedback'].append('íŒ”ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë‚´ë ¤ë³´ì„¸ìš” âš ')
            else:
                analysis['feedback'].append('íŒ” í‚¤í¬ì¸íŠ¸ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤')
            
            # ì ìˆ˜ ìƒí•œ ì„¤ì •
            analysis['posture_score'] = min(100, analysis['posture_score'])
            
            # ì „ì²´ì ì¸ í”¼ë“œë°±
            if analysis['posture_score'] >= 70:
                analysis['feedback'].insert(0, 'ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ìì„¸ì…ë‹ˆë‹¤! ğŸ‘')
            elif analysis['posture_score'] >= 40:
                analysis['feedback'].insert(0, 'ìì„¸ê°€ ê´œì°®ìŠµë‹ˆë‹¤. ì¡°ê¸ˆë§Œ ë” ê°œì„ í•´ë³´ì„¸ìš” ğŸ‘Œ')
            elif analysis['posture_score'] >= 20:
                analysis['feedback'].insert(0, 'í‚¤í¬ì¸íŠ¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìì„¸ë¥¼ ê°œì„ í•´ë³´ì„¸ìš” ğŸ“')
            else:
                analysis['feedback'].insert(0, 'ì¹´ë©”ë¼ ìœ„ì¹˜ë¥¼ ì¡°ì •í•˜ì—¬ ì „ì‹ ì´ ì˜ ë³´ì´ë„ë¡ í•´ì£¼ì„¸ìš” ğŸ“·')
                
        except Exception as e:
            logger.error(f"í¬ì¦ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            analysis['feedback'].append('í¬ì¦ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤')
            analysis['posture_score'] = 0
        
        return analysis
    
    def draw_pose(self, image: np.ndarray, keypoints: List[Dict]) -> np.ndarray:
        """
        ì´ë¯¸ì§€ì— í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ì™€ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            keypoints: í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í¬ì¦ˆê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
        """
        result_image = image.copy()
        
        # í‚¤í¬ì¸íŠ¸ë¥¼ ì¸ë±ìŠ¤ë¡œ ë§¤í•‘
        kp_dict = {kp['id']: kp for kp in keypoints}
        
        # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
        for pair in self.POSE_PAIRS:
            if pair[0] in kp_dict and pair[1] in kp_dict:
                point1 = kp_dict[pair[0]]
                point2 = kp_dict[pair[1]]
                
                cv2.line(result_image, 
                        (point1['x'], point1['y']), 
                        (point2['x'], point2['y']), 
                        (0, 255, 0), 2)
        
        # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
        for kp in keypoints:
            cv2.circle(result_image, (kp['x'], kp['y']), 5, (0, 0, 255), -1)
            cv2.putText(result_image, f"{kp['name']}", 
                       (kp['x'] + 5, kp['y'] - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
        
        return result_image


def create_pose_estimator() -> HumanPoseEstimator:
    """í¬ì¦ˆ ì¶”ì •ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    model_xml = "pose/human-pose-estimation-0001.xml"
    model_bin = "pose/human-pose-estimation-0001.bin"
    
    return HumanPoseEstimator(model_xml, model_bin, device="CPU")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    estimator = create_pose_estimator()
    
    # ì›¹ìº ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    cap = cv2.VideoCapture(0)
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # í¬ì¦ˆ ì¶”ì •
        result = estimator.estimate_pose(frame)
        
        # ê²°ê³¼ ê·¸ë¦¬ê¸°
        pose_image = estimator.draw_pose(frame, result['keypoints'])
        
        # í”¼ë“œë°± í‘œì‹œ
        y_offset = 30
        for feedback in result['analysis']['feedback']:
            cv2.putText(pose_image, feedback, (10, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            y_offset += 25
        
        cv2.imshow('Pose Estimation', pose_image)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()

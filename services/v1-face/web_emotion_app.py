#!/usr/bin/env python3
"""
ì›¹ ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì • ë¶„ì„ ì• í”Œë¦¬ì¼€ì´ì…˜
ì›ê²© ì„œë²„ì—ì„œ ì›¹ ì„œë²„ë¥¼ ë„ìš°ê³ , í´ë¼ì´ì–¸íŠ¸ì˜ ì›¹ìº ì„ ì‚¬ìš©í•˜ì—¬ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.
"""

from flask import Flask, render_template, request, jsonify, Response
import cv2
import numpy as np
import base64
import io
import time
import os
import json
from datetime import datetime
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import math
from PIL import Image

app = Flask(__name__)

class WebEmotionAnalyzer:
    def __init__(self, model_path='./models/face_landmarker.task'):
        """ì›¹ ê¸°ë°˜ ê°ì • ë¶„ì„ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.model_path = model_path
        self.detector = None
        self.session_data = []
        self.session_start_time = None
        self.frame_count = 0
        
        # ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
        self.setup_output_folders()
        
        # MediaPipe ì´ˆê¸°í™”
        self.initialize_detector()
    
    def setup_output_folders(self):
        """ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ í´ë” êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_folder = f"web_session_{timestamp}"
        
        self.folders = {
            'session': f"results/{self.session_folder}",
            'frames': f"results/{self.session_folder}/frames",
            'analysis': f"results/{self.session_folder}/analysis",
            'reports': f"results/{self.session_folder}/reports"
        }
        
        for folder in self.folders.values():
            os.makedirs(folder, exist_ok=True)
        
        print(f"ğŸ“ ì›¹ ì„¸ì…˜ í´ë” ìƒì„±: {self.session_folder}")
    
    def initialize_detector(self):
        """MediaPipe ì–¼êµ´ ëœë“œë§ˆí¬ ê°ì§€ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            base_options = python.BaseOptions(model_asset_path=self.model_path)
            options = vision.FaceLandmarkerOptions(
                base_options=base_options,
                output_face_blendshapes=True,
                output_facial_transformation_matrixes=True,
                num_faces=1
            )
            self.detector = vision.FaceLandmarker.create_from_options(options)
            print("âœ… MediaPipe ê°ì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"âŒ MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.detector = None
            return False
    
    def calculate_distance(self, point1, point2):
        """ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        return math.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2)
    
    def analyze_emotion_from_landmarks(self, face_landmarks):
        """ì–¼êµ´ ëœë“œë§ˆí¬ì—ì„œ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        if not face_landmarks or len(face_landmarks) == 0:
            return {"emotion": "unknown", "confidence": 0.0, "details": {}}
        
        landmarks = face_landmarks[0]
        
        # ì£¼ìš” ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
        LEFT_EYE_INNER = 133
        LEFT_EYE_OUTER = 33
        RIGHT_EYE_INNER = 362
        RIGHT_EYE_OUTER = 263
        MOUTH_LEFT = 61
        MOUTH_RIGHT = 291
        MOUTH_TOP = 13
        MOUTH_BOTTOM = 14
        LEFT_EYEBROW_INNER = 70
        RIGHT_EYEBROW_INNER = 300
        
        try:
            # ëˆˆ í¬ê¸° ë¶„ì„
            left_eye_width = self.calculate_distance(landmarks[LEFT_EYE_INNER], landmarks[LEFT_EYE_OUTER])
            right_eye_width = self.calculate_distance(landmarks[RIGHT_EYE_INNER], landmarks[RIGHT_EYE_OUTER])
            avg_eye_width = (left_eye_width + right_eye_width) / 2
            
            # ì… í¬ê¸° ë¶„ì„
            mouth_width = self.calculate_distance(landmarks[MOUTH_LEFT], landmarks[MOUTH_RIGHT])
            mouth_height = self.calculate_distance(landmarks[MOUTH_TOP], landmarks[MOUTH_BOTTOM])
            
            # ëˆˆì¹ ë†’ì´ ë¶„ì„
            left_eyebrow_height = landmarks[LEFT_EYEBROW_INNER].y - landmarks[LEFT_EYE_INNER].y
            right_eyebrow_height = landmarks[RIGHT_EYEBROW_INNER].y - landmarks[RIGHT_EYE_INNER].y
            avg_eyebrow_height = (left_eyebrow_height + right_eyebrow_height) / 2
            
            # ê°ì • ë¶„ì„ ë¡œì§
            emotion_scores = {
                "happy": 0.0,
                "sad": 0.0,
                "angry": 0.0,
                "surprised": 0.0,
                "neutral": 0.0,
                "confident": 0.0
            }
            
            # ë¯¸ì†Œ ê°ì§€
            mouth_corners_up = (landmarks[MOUTH_LEFT].y < landmarks[MOUTH_TOP].y and 
                               landmarks[MOUTH_RIGHT].y < landmarks[MOUTH_TOP].y)
            if mouth_corners_up and mouth_width > 0.02:
                emotion_scores["happy"] += 0.4
                emotion_scores["confident"] += 0.2
            
            # ìŠ¬í”” ê°ì§€
            if avg_eyebrow_height < -0.01:
                emotion_scores["sad"] += 0.3
            if not mouth_corners_up and mouth_width < 0.015:
                emotion_scores["sad"] += 0.2
            
            # í™”ë‚¨ ê°ì§€
            if avg_eyebrow_height < -0.005 and avg_eye_width < 0.025:
                emotion_scores["angry"] += 0.4
            
            # ë†€ëŒ ê°ì§€
            if avg_eye_width > 0.035:
                emotion_scores["surprised"] += 0.4
            
            # ìì‹ ê° ê°ì§€
            if avg_eye_width > 0.03 and mouth_corners_up:
                emotion_scores["confident"] += 0.3
            
            # ì¤‘ë¦½ ê°ì§€
            if (0.02 < avg_eye_width < 0.03 and 
                0.01 < mouth_width < 0.02 and 
                -0.005 < avg_eyebrow_height < 0.005):
                emotion_scores["neutral"] += 0.3
            
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ê°ì • ì„ íƒ
            max_emotion = max(emotion_scores, key=emotion_scores.get)
            max_score = emotion_scores[max_emotion]
            confidence = min(1.0, max_score)
            
            return {
                "emotion": max_emotion,
                "confidence": confidence,
                "details": {
                    "eye_width": avg_eye_width,
                    "mouth_width": mouth_width,
                    "mouth_height": mouth_height,
                    "eyebrow_height": avg_eyebrow_height,
                    "all_scores": emotion_scores
                }
            }
            
        except Exception as e:
            print(f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"emotion": "unknown", "confidence": 0.0, "details": {}}
    
    def get_interview_score(self, emotion_data):
        """ë©´ì ‘ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        emotion = emotion_data["emotion"]
        confidence = emotion_data["confidence"]
        
        score_map = {
            "confident": 90,
            "happy": 85,
            "neutral": 70,
            "surprised": 60,
            "sad": 40,
            "angry": 30,
            "unknown": 50
        }
        
        base_score = score_map.get(emotion, 50)
        
        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì¡°ì •
        if confidence < 0.5:
            base_score *= 0.8
        
        return min(100, max(0, int(base_score)))
    
    def analyze_frame(self, image_data):
        """ì›¹ì—ì„œ ì „ì†¡ë°›ì€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
        if not self.detector:
            return {"error": "MediaPipe ê°ì§€ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        try:
            # Base64 ì´ë¯¸ì§€ ë””ì½”ë”©
            if image_data.startswith('data:image'):
                image_data = image_data.split(',')[1]
            
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
            
            # RGBë¡œ ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            image_np = np.array(image)
            
            # MediaPipe ì´ë¯¸ì§€ ìƒì„±
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_np)
            
            # ì–¼êµ´ ëœë“œë§ˆí¬ ê°ì§€
            detection_result = self.detector.detect(mp_image)
            
            # ê°ì • ë¶„ì„
            emotion_data = self.analyze_emotion_from_landmarks(detection_result.face_landmarks)
            score = self.get_interview_score(emotion_data)
            
            # í”„ë ˆì„ ì¹´ìš´íŠ¸ ì¦ê°€
            self.frame_count += 1
            
            # ì„¸ì…˜ ë°ì´í„° ì €ì¥
            frame_data = {
                "frame_number": self.frame_count,
                "timestamp": time.time(),
                "emotion": emotion_data["emotion"],
                "confidence": emotion_data["confidence"],
                "score": score,
                "details": emotion_data["details"]
            }
            
            self.session_data.append(frame_data)
            
            # ê²°ê³¼ ë°˜í™˜
            return {
                "success": True,
                "emotion": emotion_data["emotion"],
                "confidence": round(emotion_data["confidence"], 2),
                "score": score,
                "frame_count": self.frame_count,
                "details": emotion_data["details"]
            }
            
        except Exception as e:
            return {"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
analyzer = WebEmotionAnalyzer()

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    return render_template('webcam_analyzer.html')

@app.route('/analyze', methods=['POST'])
def analyze():
    """ì´ë¯¸ì§€ ë¶„ì„ API"""
    try:
        data = request.get_json()
        image_data = data.get('image')
        
        if not image_data:
            return jsonify({"error": "ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."})
        
        result = analyzer.analyze_frame(image_data)
        return jsonify(result)
        
    except Exception as e:
        return jsonify({"error": f"ì„œë²„ ì˜¤ë¥˜: {str(e)}"})

@app.route('/session_info')
def session_info():
    """ì„¸ì…˜ ì •ë³´ API"""
    return jsonify({
        "session_folder": analyzer.session_folder,
        "frame_count": analyzer.frame_count,
        "total_data": len(analyzer.session_data)
    })

if __name__ == '__main__':
    print("ğŸ­ ì›¹ ê¸°ë°˜ ì‹¤ì‹œê°„ ê°ì • ë¶„ì„ ì„œë²„")
    print("="*50)
    
    if not analyzer.detector:
        print("âŒ MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨. ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)
    
    print("âœ… ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ")
    print("ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†: http://localhost:5000")
    print("ğŸ“ ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
    
    # Flask ì•± ì‹¤í–‰
    app.run(host='0.0.0.0', port=5000, debug=False)

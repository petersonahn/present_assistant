#!/usr/bin/env python3
"""
WSL2 í™˜ê²½ì—ì„œ ì›¹ìº ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ê°ì • ë¶„ì„
ë‹¤ì–‘í•œ ì›¹ìº  ì ‘ê·¼ ë°©ë²•ì„ ì‹œë„í•©ë‹ˆë‹¤.
"""

import cv2
import numpy as np
import time
import os
import json
from datetime import datetime
import math
from typing import List, Dict, Tuple
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

class WebcamAnalyzer:
    def __init__(self, model_path='./models/face_landmarker.task'):
        """ì›¹ìº  ë¶„ì„ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.model_path = model_path
        self.detector = None
        self.session_data = []
        self.session_start_time = None
        self.frame_count = 0
        self.cap = None
        
        # ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
        self.setup_output_folders()
        
        # MediaPipe ì´ˆê¸°í™”
        self.initialize_detector()
    
    def setup_output_folders(self):
        """ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ í´ë” êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_folder = f"webcam_{timestamp}"
        
        self.folders = {
            'session': f"results/{self.session_folder}",
            'frames': f"results/{self.session_folder}/frames",
            'analysis': f"results/{self.session_folder}/analysis",
            'reports': f"results/{self.session_folder}/reports"
        }
        
        for folder in self.folders.values():
            os.makedirs(folder, exist_ok=True)
        
        print(f"ğŸ“ ì›¹ìº  ì„¸ì…˜ í´ë” ìƒì„±: {self.session_folder}")
    
    def initialize_detector(self):
        """MediaPipe ì–¼êµ´ ëœë“œë§ˆí¬ ê°ì§€ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            base_options = python.BaseOptions(model_asset_path=self.model_path)
            options = vision.FaceLandmarkerOptions(
                base_options=base_options,
                output_face_blendshapes=True,
                output_facial_transformation_matrixes=True,
                num_faces=1
            )
            self.detector = vision.FaceLandmarker.create_from_options(options)
            print("âœ… MediaPipe ê°ì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.detector = None
    
    def find_webcam(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì›¹ìº ì„ ì°¾ìŠµë‹ˆë‹¤."""
        print("ğŸ” ì›¹ìº ì„ ì°¾ëŠ” ì¤‘...")
        
        # ë‹¤ì–‘í•œ ì›¹ìº  ì¸ë±ìŠ¤ ì‹œë„
        for camera_index in range(5):  # 0-4ê¹Œì§€ ì‹œë„
            print(f"   ì¹´ë©”ë¼ {camera_index} ì‹œë„ ì¤‘...")
            cap = cv2.VideoCapture(camera_index)
            
            if cap.isOpened():
                ret, frame = cap.read()
                if ret and frame is not None:
                    print(f"âœ… ì¹´ë©”ë¼ {camera_index} ë°œê²¬!")
                    return cap, camera_index
                else:
                    cap.release()
            else:
                cap.release()
        
        # USB ì›¹ìº  ì‹œë„
        usb_cameras = ['/dev/video0', '/dev/video1', '/dev/video2']
        for camera_path in usb_cameras:
            if os.path.exists(camera_path):
                print(f"   USB ì¹´ë©”ë¼ {camera_path} ì‹œë„ ì¤‘...")
                cap = cv2.VideoCapture(camera_path)
                if cap.isOpened():
                    ret, frame = cap.read()
                    if ret and frame is not None:
                        print(f"âœ… USB ì¹´ë©”ë¼ {camera_path} ë°œê²¬!")
                        return cap, camera_path
                    else:
                        cap.release()
        
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì›¹ìº ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    
    def calculate_distance(self, point1, point2):
        """ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        return math.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2)
    
    def analyze_emotion_from_landmarks(self, face_landmarks):
        """ì–¼êµ´ ëœë“œë§ˆí¬ì—ì„œ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        if not face_landmarks or len(face_landmarks) == 0:
            return {"emotion": "unknown", "confidence": 0.0, "details": {}}
        
        landmarks = face_landmarks[0]
        
        # ì£¼ìš” ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
        LEFT_EYE_INNER = 133
        LEFT_EYE_OUTER = 33
        RIGHT_EYE_INNER = 362
        RIGHT_EYE_OUTER = 263
        MOUTH_LEFT = 61
        MOUTH_RIGHT = 291
        MOUTH_TOP = 13
        MOUTH_BOTTOM = 14
        LEFT_EYEBROW_INNER = 70
        LEFT_EYEBROW_OUTER = 46
        RIGHT_EYEBROW_INNER = 300
        RIGHT_EYEBROW_OUTER = 276
        
        try:
            # ëˆˆ í¬ê¸° ë¶„ì„
            left_eye_width = self.calculate_distance(landmarks[LEFT_EYE_INNER], landmarks[LEFT_EYE_OUTER])
            right_eye_width = self.calculate_distance(landmarks[RIGHT_EYE_INNER], landmarks[RIGHT_EYE_OUTER])
            avg_eye_width = (left_eye_width + right_eye_width) / 2
            
            # ì… í¬ê¸° ë¶„ì„
            mouth_width = self.calculate_distance(landmarks[MOUTH_LEFT], landmarks[MOUTH_RIGHT])
            mouth_height = self.calculate_distance(landmarks[MOUTH_TOP], landmarks[MOUTH_BOTTOM])
            
            # ëˆˆì¹ ë†’ì´ ë¶„ì„
            left_eyebrow_height = landmarks[LEFT_EYEBROW_INNER].y - landmarks[LEFT_EYE_INNER].y
            right_eyebrow_height = landmarks[RIGHT_EYEBROW_INNER].y - landmarks[RIGHT_EYE_INNER].y
            avg_eyebrow_height = (left_eyebrow_height + right_eyebrow_height) / 2
            
            # ê°ì • ë¶„ì„ ë¡œì§
            emotion_scores = {
                "happy": 0.0,
                "sad": 0.0,
                "angry": 0.0,
                "surprised": 0.0,
                "neutral": 0.0,
                "confident": 0.0
            }
            
            # ë¯¸ì†Œ ê°ì§€
            mouth_corners_up = (landmarks[MOUTH_LEFT].y < landmarks[MOUTH_TOP].y and 
                               landmarks[MOUTH_RIGHT].y < landmarks[MOUTH_TOP].y)
            if mouth_corners_up and mouth_width > 0.02:
                emotion_scores["happy"] += 0.4
                emotion_scores["confident"] += 0.2
            
            # ìŠ¬í”” ê°ì§€
            if avg_eyebrow_height < -0.01:
                emotion_scores["sad"] += 0.3
            if not mouth_corners_up and mouth_width < 0.015:
                emotion_scores["sad"] += 0.2
            
            # í™”ë‚¨ ê°ì§€
            if avg_eyebrow_height < -0.005 and avg_eye_width < 0.025:
                emotion_scores["angry"] += 0.4
            
            # ë†€ëŒ ê°ì§€
            if avg_eye_width > 0.035:
                emotion_scores["surprised"] += 0.4
            
            # ìì‹ ê° ê°ì§€
            if avg_eye_width > 0.03 and mouth_corners_up:
                emotion_scores["confident"] += 0.3
            
            # ì¤‘ë¦½ ê°ì§€
            if (0.02 < avg_eye_width < 0.03 and 
                0.01 < mouth_width < 0.02 and 
                -0.005 < avg_eyebrow_height < 0.005):
                emotion_scores["neutral"] += 0.3
            
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ê°ì • ì„ íƒ
            max_emotion = max(emotion_scores, key=emotion_scores.get)
            max_score = emotion_scores[max_emotion]
            confidence = min(1.0, max_score)
            
            return {
                "emotion": max_emotion,
                "confidence": confidence,
                "details": {
                    "eye_width": avg_eye_width,
                    "mouth_width": mouth_width,
                    "mouth_height": mouth_height,
                    "eyebrow_height": avg_eyebrow_height,
                    "all_scores": emotion_scores
                }
            }
            
        except Exception as e:
            print(f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"emotion": "unknown", "confidence": 0.0, "details": {}}
    
    def get_interview_score(self, emotion_data):
        """ë©´ì ‘ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        emotion = emotion_data["emotion"]
        confidence = emotion_data["confidence"]
        
        score_map = {
            "confident": 90,
            "happy": 85,
            "neutral": 70,
            "surprised": 60,
            "sad": 40,
            "angry": 30,
            "unknown": 50
        }
        
        base_score = score_map.get(emotion, 50)
        
        # ì‹ ë¢°ë„ì— ë”°ë¥¸ ì¡°ì •
        if confidence < 0.5:
            base_score *= 0.8
        
        return min(100, max(0, int(base_score)))
    
    def draw_landmarks_and_info(self, frame, detection_result, emotion_data, score):
        """í”„ë ˆì„ì— ëœë“œë§ˆí¬ì™€ ì •ë³´ë¥¼ ê·¸ë¦½ë‹ˆë‹¤."""
        annotated_frame = frame.copy()
        
        if detection_result.face_landmarks:
            # ì–¼êµ´ ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
            for face_landmarks in detection_result.face_landmarks:
                for landmark in face_landmarks:
                    x = int(landmark.x * frame.shape[1])
                    y = int(landmark.y * frame.shape[0])
                    cv2.circle(annotated_frame, (x, y), 1, (0, 255, 0), -1)
        
        # ì •ë³´ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        emotion = emotion_data["emotion"]
        confidence = emotion_data["confidence"]
        
        # ë°°ê²½ ì‚¬ê°í˜•
        cv2.rectangle(annotated_frame, (10, 10), (400, 120), (0, 0, 0), -1)
        cv2.rectangle(annotated_frame, (10, 10), (400, 120), (255, 255, 255), 2)
        
        # í…ìŠ¤íŠ¸
        cv2.putText(annotated_frame, f"Emotion: {emotion}", (20, 35), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(annotated_frame, f"Confidence: {confidence:.2f}", (20, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(annotated_frame, f"Score: {score}/100", (20, 85), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(annotated_frame, f"Frame: {self.frame_count}", (20, 110), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return annotated_frame
    
    def save_frame_data(self, frame, emotion_data, score):
        """í”„ë ˆì„ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        timestamp = time.time()
        
        frame_data = {
            "frame_number": self.frame_count,
            "timestamp": timestamp,
            "emotion": emotion_data["emotion"],
            "confidence": emotion_data["confidence"],
            "score": score,
            "details": emotion_data["details"]
        }
        
        self.session_data.append(frame_data)
        
        # ì£¼ê¸°ì ìœ¼ë¡œ í”„ë ˆì„ ì´ë¯¸ì§€ ì €ì¥ (ë§¤ 30í”„ë ˆì„ë§ˆë‹¤)
        if self.frame_count % 30 == 0:
            frame_filename = f"frame_{self.frame_count:06d}.jpg"
            frame_path = os.path.join(self.folders['frames'], frame_filename)
            cv2.imwrite(frame_path, frame)
    
    def run_webcam_analysis(self):
        """ì›¹ìº  ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        if not self.detector:
            print("âŒ ê°ì§€ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ì›¹ìº  ì°¾ê¸°
        self.cap, camera_info = self.find_webcam()
        if self.cap is None:
            print("âŒ ì›¹ìº ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ í•´ê²° ë°©ë²•:")
            print("   1. ì›¹ìº ì´ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
            print("   2. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ ì›¹ìº ì„ ì‚¬ìš©í•˜ê³  ìˆì§€ ì•Šì€ì§€ í™•ì¸í•˜ì„¸ìš”")
            print("   3. Windowsì—ì„œ ì§ì ‘ ì‹¤í–‰í•´ë³´ì„¸ìš”: run_on_windows.bat")
            return
        
        print(f"ğŸ¥ ì›¹ìº  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì¹´ë©”ë¼: {camera_info})")
        print("ğŸ“ ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ê±°ë‚˜ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
        
        self.session_start_time = time.time()
        
        try:
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    print("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                self.frame_count += 1
                
                # MediaPipeìš© ì´ë¯¸ì§€ ë³€í™˜
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
                
                # ì–¼êµ´ ëœë“œë§ˆí¬ ê°ì§€
                detection_result = self.detector.detect(mp_image)
                
                # ê°ì • ë¶„ì„
                emotion_data = self.analyze_emotion_from_landmarks(detection_result.face_landmarks)
                score = self.get_interview_score(emotion_data)
                
                # í”„ë ˆì„ì— ì •ë³´ ê·¸ë¦¬ê¸°
                annotated_frame = self.draw_landmarks_and_info(frame, detection_result, emotion_data, score)
                
                # í”„ë ˆì„ ë°ì´í„° ì €ì¥
                self.save_frame_data(frame, emotion_data, score)
                
                # í™”ë©´ì— í‘œì‹œ
                try:
                    cv2.imshow('Webcam Emotion Analysis', annotated_frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                except Exception as e:
                    print(f"GUI í‘œì‹œ ì˜¤ë¥˜ (ì •ìƒ): {e}")
                    # GUI í‘œì‹œ ì‹¤íŒ¨ ì‹œì—ë„ ê³„ì† ì§„í–‰
                
                # ì§„í–‰ë¥  í‘œì‹œ (ë§¤ 30í”„ë ˆì„ë§ˆë‹¤)
                if self.frame_count % 30 == 0:
                    elapsed = time.time() - self.session_start_time
                    print(f"\râ±ï¸ ë¶„ì„ ì¤‘... {self.frame_count} í”„ë ˆì„ ({elapsed:.1f}ì´ˆ)", end="", flush=True)
                
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        finally:
            if self.cap:
                self.cap.release()
            try:
                cv2.destroyAllWindows()
            except:
                pass
            self.generate_summary_report()
    
    def generate_summary_report(self):
        """ì¢…í•© ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.session_data:
            print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„± ì¤‘...")
        print("="*60)
        
        # ê¸°ë³¸ í†µê³„ ê³„ì‚°
        total_frames = len(self.session_data)
        session_duration = time.time() - self.session_start_time if self.session_start_time else 0
        
        # ê°ì •ë³„ í†µê³„
        emotion_counts = {}
        total_score = 0
        confidence_sum = 0
        
        for data in self.session_data:
            emotion = data["emotion"]
            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
            total_score += data["score"]
            confidence_sum += data["confidence"]
        
        # í‰ê·  ê³„ì‚°
        avg_score = total_score / total_frames if total_frames > 0 else 0
        avg_confidence = confidence_sum / total_frames if total_frames > 0 else 0
        
        # ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚œ ê°ì •
        dominant_emotion = max(emotion_counts, key=emotion_counts.get) if emotion_counts else "unknown"
        
        # ë¦¬í¬íŠ¸ ë°ì´í„° ìƒì„±
        report = {
            "session_info": {
                "session_folder": self.session_folder,
                "start_time": datetime.fromtimestamp(self.session_start_time).isoformat() if self.session_start_time else None,
                "duration_seconds": session_duration,
                "total_frames": total_frames,
                "fps": total_frames / session_duration if session_duration > 0 else 0,
                "mode": "webcam"
            },
            "analysis_results": {
                "average_score": round(avg_score, 2),
                "average_confidence": round(avg_confidence, 2),
                "dominant_emotion": dominant_emotion,
                "emotion_distribution": emotion_counts,
                "score_range": {
                    "min": min(data["score"] for data in self.session_data),
                    "max": max(data["score"] for data in self.session_data)
                }
            },
            "recommendations": self.generate_recommendations(avg_score, dominant_emotion, emotion_counts),
            "frame_data": self.session_data
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        report_path = os.path.join(self.folders['reports'], 'summary_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_text_report(report)
        
        print(f"âœ… ì¢…í•© ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"   ğŸ“ ì„¸ì…˜ í´ë”: {self.session_folder}")
        print(f"   ğŸ“Š í‰ê·  ì ìˆ˜: {avg_score:.1f}/100")
        print(f"   ğŸ˜Š ì£¼ìš” ê°ì •: {dominant_emotion}")
        print(f"   ğŸ“ˆ ì‹ ë¢°ë„: {avg_confidence:.2f}")
        print(f"   ğŸ“ ê²°ê³¼ ìœ„ì¹˜: results/{self.session_folder}/")
    
    def generate_recommendations(self, avg_score, dominant_emotion, emotion_counts):
        """ê°œì„  ê¶Œì¥ì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        recommendations = []
        
        if avg_score >= 80:
            recommendations.append("í›Œë¥­í•œ ë©´ì ‘ í‘œì •ì…ë‹ˆë‹¤! í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ì„¸ìš”.")
        elif avg_score >= 60:
            recommendations.append("ì¢‹ì€ í‘œì •ì´ì§€ë§Œ ë” ê°œì„ í•  ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.")
        else:
            recommendations.append("ë©´ì ‘ í‘œì •ì„ ê°œì„ í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        if dominant_emotion == "sad":
            recommendations.append("ë” ë°ê³  ê¸ì •ì ì¸ í‘œì •ì„ ì—°ìŠµí•´ë³´ì„¸ìš”.")
        elif dominant_emotion == "angry":
            recommendations.append("ê¸´ì¥ì„ í’€ê³  ì°¨ë¶„í•œ í‘œì •ì„ ì—°ìŠµí•´ë³´ì„¸ìš”.")
        elif dominant_emotion == "neutral":
            recommendations.append("ìì—°ìŠ¤ëŸ¬ìš´ ë¯¸ì†Œë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”.")
        
        if emotion_counts.get("confident", 0) < emotion_counts.get("neutral", 0):
            recommendations.append("ìì‹ ê° ìˆëŠ” í‘œì •ì„ ë” ìì£¼ ì—°ìŠµí•´ë³´ì„¸ìš”.")
        
        return recommendations
    
    def generate_text_report(self, report):
        """í…ìŠ¤íŠ¸ í˜•íƒœì˜ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        report_path = os.path.join(self.folders['reports'], 'summary_report.txt')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("ğŸ­ ë©´ì ‘ í‘œì • ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ (ì›¹ìº )\n")
            f.write("="*60 + "\n\n")
            
            # ì„¸ì…˜ ì •ë³´
            f.write("ğŸ“‹ ì„¸ì…˜ ì •ë³´:\n")
            f.write(f"   ì„¸ì…˜ í´ë”: {report['session_info']['session_folder']}\n")
            f.write(f"   ë¶„ì„ ëª¨ë“œ: {report['session_info']['mode']}\n")
            f.write(f"   ë¶„ì„ ì‹œê°„: {report['session_info']['duration_seconds']:.1f}ì´ˆ\n")
            f.write(f"   ì´ í”„ë ˆì„: {report['session_info']['total_frames']}\n")
            f.write(f"   í‰ê·  FPS: {report['session_info']['fps']:.1f}\n\n")
            
            # ë¶„ì„ ê²°ê³¼
            f.write("ğŸ“Š ë¶„ì„ ê²°ê³¼:\n")
            f.write(f"   í‰ê·  ì ìˆ˜: {report['analysis_results']['average_score']}/100\n")
            f.write(f"   í‰ê·  ì‹ ë¢°ë„: {report['analysis_results']['average_confidence']:.2f}\n")
            f.write(f"   ì£¼ìš” ê°ì •: {report['analysis_results']['dominant_emotion']}\n")
            f.write(f"   ì ìˆ˜ ë²”ìœ„: {report['analysis_results']['score_range']['min']}-{report['analysis_results']['score_range']['max']}\n\n")
            
            # ê°ì • ë¶„í¬
            f.write("ğŸ˜Š ê°ì • ë¶„í¬:\n")
            for emotion, count in report['analysis_results']['emotion_distribution'].items():
                percentage = (count / report['session_info']['total_frames']) * 100
                f.write(f"   {emotion}: {count}íšŒ ({percentage:.1f}%)\n")
            f.write("\n")
            
            # ê¶Œì¥ì‚¬í•­
            f.write("ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­:\n")
            for i, rec in enumerate(report['recommendations'], 1):
                f.write(f"   {i}. {rec}\n")
            f.write("\n")
            
            f.write("="*60 + "\n")
            f.write("ë¶„ì„ ì™„ë£Œ ì‹œê°„: " + datetime.now().strftime("%Y-%m-%d %H:%M:%S") + "\n")
            f.write("="*60 + "\n")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ­ ì›¹ìº  ë©´ì ‘ í‘œì • ë¶„ì„ ì‹œìŠ¤í…œ")
    print("="*50)
    print("ğŸ“ ì´ í”„ë¡œê·¸ë¨ì€ ì›¹ìº ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    print("="*50)
    
    # ê²°ê³¼ í´ë” ìƒì„±
    os.makedirs("results", exist_ok=True)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
    analyzer = WebcamAnalyzer()
    analyzer.run_webcam_analysis()

if __name__ == "__main__":
    main()

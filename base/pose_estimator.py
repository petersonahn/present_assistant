"""
Human Pose Estimation using OpenVINO
ì‹¤ì‹œê°„ ë©´ì ‘ í”¼ë“œë°± ì‹œìŠ¤í…œ - í¬ì¦ˆ ê°ì§€ ëª¨ë“ˆ
"""

import cv2
import numpy as np
from openvino.runtime import Core
from typing import List, Tuple, Dict, Optional
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HumanPoseEstimator:
    """OpenVINO ê¸°ë°˜ ì¸ê°„ í¬ì¦ˆ ì¶”ì • í´ë˜ìŠ¤"""
    
    # COCO í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ ì¸ë±ìŠ¤ (18ê°œ ê´€ì ˆ)
    POSE_PAIRS = [
        (1, 2), (1, 5), (2, 3), (3, 4), (5, 6), (6, 7),
        (1, 8), (8, 9), (9, 10), (1, 11), (11, 12), (12, 13),
        (1, 0), (0, 14), (14, 16), (0, 15), (15, 17)
    ]
    
    # í‚¤í¬ì¸íŠ¸ ì´ë¦„ ë§¤í•‘
    KEYPOINT_NAMES = [
        "nose", "neck", "r_shoulder", "r_elbow", "r_wrist",
        "l_shoulder", "l_elbow", "l_wrist", "r_hip", "r_knee",
        "r_ankle", "l_hip", "l_knee", "l_ankle", "r_eye",
        "l_eye", "r_ear", "l_ear"
    ]
    
    def __init__(self, model_xml_path: str, model_bin_path: str, device: str = "CPU"):
        """
        í¬ì¦ˆ ì¶”ì •ê¸° ì´ˆê¸°í™”
        
        Args:
            model_xml_path: OpenVINO XML ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            model_bin_path: OpenVINO BIN ëª¨ë¸ íŒŒì¼ ê²½ë¡œ 
            device: ì¶”ë¡  ë””ë°”ì´ìŠ¤ ("CPU", "GPU", "MYRIAD" ë“±)
        """
        self.device = device
        self.model_xml_path = model_xml_path
        self.model_bin_path = model_bin_path
        
        # OpenVINO ì½”ì–´ ë° ëª¨ë¸ ë¡œë“œ
        self.core = Core()
        self.model = self.core.read_model(model_xml_path)
        self.compiled_model = self.core.compile_model(self.model, device)
        
        # ì…ì¶œë ¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        self.input_layer = self.compiled_model.input(0)
        self.output_layer = self.compiled_model.output(0)
        
        # ì…ë ¥ í¬ê¸° ì •ë³´
        self.input_shape = self.input_layer.shape
        self.input_height = self.input_shape[2]  # 256
        self.input_width = self.input_shape[3]   # 456
        
        logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_xml_path}")
        logger.info(f"ì…ë ¥ í¬ê¸°: {self.input_width}x{self.input_height}")
        logger.info(f"ë””ë°”ì´ìŠ¤: {device}")
    
    def preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR í˜•ì‹)
            
        Returns:
            ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ
        """
        # RGBë¡œ ë³€í™˜
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # í¬ê¸° ì¡°ì •
        resized_image = cv2.resize(image_rgb, (self.input_width, self.input_height))
        
        # ì •ê·œí™” (0-1 ë²”ìœ„ë¡œ)
        normalized_image = resized_image.astype(np.float32) / 255.0
        
        # ì°¨ì› ë³€ê²½: (H, W, C) -> (1, C, H, W)
        input_tensor = np.transpose(normalized_image, (2, 0, 1))
        input_tensor = np.expand_dims(input_tensor, axis=0)
        
        return input_tensor
    
    def postprocess_output(self, output: np.ndarray, original_shape: Tuple[int, int]) -> List[Dict]:
        """
        ëª¨ë¸ ì¶œë ¥ í›„ì²˜ë¦¬
        
        Args:
            output: ëª¨ë¸ ì¶œë ¥ í…ì„œ
            original_shape: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (height, width)
            
        Returns:
            ê°ì§€ëœ í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        original_height, original_width = original_shape
        
        # ì¶œë ¥ í˜•íƒœ: [1, 38, 32, 57] (PAFs + keypoints heatmaps)
        # ì²˜ìŒ 19ê°œ ì±„ë„: Part Affinity Fields (PAFs)
        # ë‹¤ìŒ 19ê°œ ì±„ë„: í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ (ë°°ê²½ + 18ê°œ ê´€ì ˆ)
        
        output = output[0]  # ë°°ì¹˜ ì°¨ì› ì œê±°
        
        # í‚¤í¬ì¸íŠ¸ íˆíŠ¸ë§µ ì¶”ì¶œ (ì±„ë„ 19-37, ì¸ë±ìŠ¤ 19:38)
        keypoint_heatmaps = output[19:38]  # 19ê°œ íˆíŠ¸ë§µ (ë°°ê²½ + 18ê°œ í‚¤í¬ì¸íŠ¸)
        
        keypoints = []
        
        # ê° í‚¤í¬ì¸íŠ¸ì— ëŒ€í•´ ìµœëŒ€ê°’ ìœ„ì¹˜ ì°¾ê¸°
        for i in range(1, len(keypoint_heatmaps)):  # ë°°ê²½(0ë²ˆ) ì œì™¸í•˜ê³  1-18ë²ˆ í‚¤í¬ì¸íŠ¸
            heatmap = keypoint_heatmaps[i]
            
            # ìµœëŒ€ê°’ê³¼ ìœ„ì¹˜ ì°¾ê¸°
            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(heatmap)
            
            # ì‹ ë¢°ë„ ì„ê³„ê°’ ì²´í¬
            if max_val > 0.1:  # ì„ê³„ê°’ ì¡°ì • ê°€ëŠ¥
                # íˆíŠ¸ë§µ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                x = int(max_loc[0] * original_width / heatmap.shape[1])
                y = int(max_loc[1] * original_height / heatmap.shape[0])
                
                keypoints.append({
                    'id': i - 1,  # 0-17 ì¸ë±ìŠ¤ë¡œ ì¡°ì •
                    'name': self.KEYPOINT_NAMES[i - 1],
                    'x': x,
                    'y': y,
                    'confidence': float(max_val)
                })
        
        return keypoints
    
    def estimate_pose(self, image: np.ndarray) -> Dict:
        """
        ì´ë¯¸ì§€ì—ì„œ í¬ì¦ˆ ì¶”ì • ìˆ˜í–‰
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR í˜•ì‹)
            
        Returns:
            í¬ì¦ˆ ì¶”ì • ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        original_height, original_width = image.shape[:2]
        
        # ì „ì²˜ë¦¬
        input_tensor = self.preprocess_image(image)
        
        # ì¶”ë¡  ì‹¤í–‰
        result = self.compiled_model([input_tensor])
        output = result[self.output_layer]
        
        # í›„ì²˜ë¦¬
        keypoints = self.postprocess_output(output, (original_height, original_width))
        
        # í¬ì¦ˆ ë¶„ì„
        pose_analysis = self.analyze_pose(keypoints)
        
        return {
            'keypoints': keypoints,
            'analysis': pose_analysis,
            'image_shape': (original_height, original_width)
        }
    
    def analyze_pose(self, keypoints: List[Dict]) -> Dict:
        """
        í¬ì¦ˆ ë¶„ì„ ë° í”¼ë“œë°± ìƒì„±
        
        Args:
            keypoints: ê°ì§€ëœ í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í¬ì¦ˆ ë¶„ì„ ê²°ê³¼
        """
        analysis = {
            'posture_score': 0,
            'shoulder_balance': 'unknown',
            'head_position': 'unknown',
            'arm_position': 'unknown',
            'feedback': []
        }
        
        # í‚¤í¬ì¸íŠ¸ë¥¼ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
        kp_dict = {kp['name']: kp for kp in keypoints}
        
        try:
            # ì–´ê¹¨ ê· í˜• ì²´í¬
            if 'l_shoulder' in kp_dict and 'r_shoulder' in kp_dict:
                left_shoulder = kp_dict['l_shoulder']
                right_shoulder = kp_dict['r_shoulder']
                
                shoulder_diff = abs(left_shoulder['y'] - right_shoulder['y'])
                
                if shoulder_diff < 20:
                    analysis['shoulder_balance'] = 'balanced'
                    analysis['posture_score'] += 30
                    analysis['feedback'].append('ì–´ê¹¨ ìœ„ì¹˜ê°€ ê· í˜•ì¡í˜€ ìˆì–´ìš” âœ“')
                else:
                    analysis['shoulder_balance'] = 'unbalanced'
                    analysis['feedback'].append('ì–´ê¹¨ë¥¼ ìˆ˜í‰ìœ¼ë¡œ ë§ì¶°ë³´ì„¸ìš” âš ')
            
            # ëª©/ë¨¸ë¦¬ ìœ„ì¹˜ ì²´í¬
            if 'neck' in kp_dict and 'nose' in kp_dict:
                neck = kp_dict['neck']
                nose = kp_dict['nose']
                
                # ëª©ê³¼ ì½”ì˜ ìˆ˜ì§ ì •ë ¬ ì²´í¬
                head_tilt = abs(neck['x'] - nose['x'])
                
                if head_tilt < 30:
                    analysis['head_position'] = 'straight'
                    analysis['posture_score'] += 25
                    analysis['feedback'].append('ë¨¸ë¦¬ ìœ„ì¹˜ê°€ ë°”ë¥¸ ìì„¸ì˜ˆìš” âœ“')
                else:
                    analysis['head_position'] = 'tilted'
                    analysis['feedback'].append('ë¨¸ë¦¬ë¥¼ ê³§ê²Œ ì„¸ì›Œë³´ì„¸ìš” âš ')
            
            # íŒ” ìœ„ì¹˜ ì²´í¬
            arm_positions = []
            for side in ['l', 'r']:
                shoulder_key = f'{side}_shoulder'
                elbow_key = f'{side}_elbow'
                
                if shoulder_key in kp_dict and elbow_key in kp_dict:
                    shoulder = kp_dict[shoulder_key]
                    elbow = kp_dict[elbow_key]
                    
                    # íŒ”ê¿ˆì¹˜ê°€ ì–´ê¹¨ë³´ë‹¤ ì•„ë˜ì— ìˆëŠ”ì§€ ì²´í¬
                    if elbow['y'] > shoulder['y']:
                        arm_positions.append('natural')
                    else:
                        arm_positions.append('raised')
            
            if arm_positions:
                if all(pos == 'natural' for pos in arm_positions):
                    analysis['arm_position'] = 'natural'
                    analysis['posture_score'] += 25
                    analysis['feedback'].append('íŒ” ìì„¸ê°€ ìì—°ìŠ¤ëŸ¬ì›Œìš” âœ“')
                else:
                    analysis['arm_position'] = 'raised'
                    analysis['feedback'].append('íŒ”ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë‚´ë ¤ë³´ì„¸ìš” âš ')
            
            # ì „ì²´ì ì¸ í”¼ë“œë°±
            if analysis['posture_score'] >= 70:
                analysis['feedback'].insert(0, 'ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ìì„¸ì…ë‹ˆë‹¤! ğŸ‘')
            elif analysis['posture_score'] >= 40:
                analysis['feedback'].insert(0, 'ìì„¸ê°€ ê´œì°®ìŠµë‹ˆë‹¤. ì¡°ê¸ˆë§Œ ë” ê°œì„ í•´ë³´ì„¸ìš” ğŸ‘Œ')
            else:
                analysis['feedback'].insert(0, 'ìì„¸ë¥¼ ê°œì„ í•´ë³´ì„¸ìš” ğŸ“')
                
        except Exception as e:
            logger.error(f"í¬ì¦ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            analysis['feedback'].append('í¬ì¦ˆ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤')
        
        return analysis
    
    def draw_pose(self, image: np.ndarray, keypoints: List[Dict]) -> np.ndarray:
        """
        ì´ë¯¸ì§€ì— í¬ì¦ˆ í‚¤í¬ì¸íŠ¸ì™€ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸°
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            keypoints: í‚¤í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í¬ì¦ˆê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€
        """
        result_image = image.copy()
        
        # í‚¤í¬ì¸íŠ¸ë¥¼ ì¸ë±ìŠ¤ë¡œ ë§¤í•‘
        kp_dict = {kp['id']: kp for kp in keypoints}
        
        # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
        for pair in self.POSE_PAIRS:
            if pair[0] in kp_dict and pair[1] in kp_dict:
                point1 = kp_dict[pair[0]]
                point2 = kp_dict[pair[1]]
                
                cv2.line(result_image, 
                        (point1['x'], point1['y']), 
                        (point2['x'], point2['y']), 
                        (0, 255, 0), 2)
        
        # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
        for kp in keypoints:
            cv2.circle(result_image, (kp['x'], kp['y']), 5, (0, 0, 255), -1)
            cv2.putText(result_image, f"{kp['name']}", 
                       (kp['x'] + 5, kp['y'] - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1)
        
        return result_image


def create_pose_estimator() -> HumanPoseEstimator:
    """í¬ì¦ˆ ì¶”ì •ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    model_xml = "pose/human-pose-estimation-0001.xml"
    model_bin = "pose/human-pose-estimation-0001.bin"
    
    return HumanPoseEstimator(model_xml, model_bin, device="CPU")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    estimator = create_pose_estimator()
    
    # ì›¹ìº ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    cap = cv2.VideoCapture(0)
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # í¬ì¦ˆ ì¶”ì •
        result = estimator.estimate_pose(frame)
        
        # ê²°ê³¼ ê·¸ë¦¬ê¸°
        pose_image = estimator.draw_pose(frame, result['keypoints'])
        
        # í”¼ë“œë°± í‘œì‹œ
        y_offset = 30
        for feedback in result['analysis']['feedback']:
            cv2.putText(pose_image, feedback, (10, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            y_offset += 25
        
        cv2.imshow('Pose Estimation', pose_image)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
